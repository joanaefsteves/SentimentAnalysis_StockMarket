{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fed63b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## <center> <b> Stock Sentiment </center>\n",
    "## <center> Predicting market behavior from tweets </center> <br>\n",
    "##  <center> <b> TRANSFORMER ENCODERS </center> <br>\n",
    "## <center> Spring Semester 2024-2025 <center>\n",
    "\n",
    "<center> Group 35: <center>\n",
    "<center>Joana Esteves, 20240746 <br><center>\n",
    "<center>José Cavaco, 20240513 <br><center>\n",
    "<center> Leonardo Di Caterina 20240485<br><center>\n",
    "<center>Matilde Miguel, 20240549 <br><center>\n",
    "<center>Rita Serra, 20240515 <br><center>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a2240",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d69c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanaesteves/Desktop/MDSAA-DS/S2/T4/TM/.TM_Project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85cfc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Preprocess\n",
    "from src.preprocessing import PreprocessingPretrained\n",
    "\n",
    "# Model\n",
    "from src.tranformer_encoder import TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c370e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('../Data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3728d",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d095794",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet = \"vinai/bertweet-base\"\n",
    "finbert = \"yiyanghkust/finbert-tone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c946fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models \n",
    "\n",
    "Finbert = TransformerEncoder(num_classes=3, model_name=finbert, base_model=\"BERT\")\n",
    "Bertweet = TransformerEncoder(num_classes=3, model_name=bertweet, base_model=\"ROBERTA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f2d57",
   "metadata": {},
   "source": [
    "# Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8697eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "            train_df['text'], train_df['label'], \n",
    "            test_size=0.2, stratify=train_df['label'], random_state=seed\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d6a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----BERTWEET-----\n",
      "Max tokens in train set: 99\n",
      "Mean tokens: 23.20\n",
      "95th percentile tokens: 42.0\n",
      "-----FINBERT-----\n",
      "Max tokens in train set: 80\n",
      "Mean tokens: 26.31\n",
      "95th percentile tokens: 51.0\n"
     ]
    }
   ],
   "source": [
    "tokenizer_bertweet = AutoTokenizer.from_pretrained(bertweet)\n",
    "tokenizer_finbert = AutoTokenizer.from_pretrained(finbert)\n",
    "\n",
    "lengths_bertweet = [len(tokenizer_bertweet.tokenize(text)) for text in X_train]\n",
    "lengths_finbert = [len(tokenizer_finbert.tokenize(text)) for text in X_train]\n",
    "\n",
    "print('-----BERTWEET-----')\n",
    "print(f'Max tokens in train set: {max(lengths_bertweet)}')\n",
    "print(f\"Mean tokens: {np.mean(lengths_bertweet):.2f}\")\n",
    "print(f\"95th percentile tokens: {np.percentile(lengths_bertweet, 95)}\")\n",
    "print('-----FINBERT-----')\n",
    "print(f'Max tokens in train set: {max(lengths_finbert)}')\n",
    "print(f\"Mean tokens: {np.mean(lengths_finbert):.2f}\")\n",
    "print(f\"95th percentile tokens: {np.percentile(lengths_finbert, 95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "997deb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light preprocessing\n",
    "preprocessor = PreprocessingPretrained(translate=True)\n",
    "\n",
    "X_train_prep = preprocessor.preprocess(X_train)\n",
    "X_val_prep = preprocessor.preprocess(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dabcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7634/7634 [00:00<00:00, 20217.97 examples/s]\n",
      "Map: 100%|██████████| 1909/1909 [00:00<00:00, 29335.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2390' max='2390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2390/2390 11:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.027896</td>\n",
       "      <td>0.792038</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.718998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.043900</td>\n",
       "      <td>0.685775</td>\n",
       "      <td>0.756941</td>\n",
       "      <td>0.691084</td>\n",
       "      <td>0.746419</td>\n",
       "      <td>0.708894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.885900</td>\n",
       "      <td>0.669761</td>\n",
       "      <td>0.804610</td>\n",
       "      <td>0.743891</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>0.747187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.785800</td>\n",
       "      <td>0.628902</td>\n",
       "      <td>0.706129</td>\n",
       "      <td>0.660319</td>\n",
       "      <td>0.761056</td>\n",
       "      <td>0.675595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.715600</td>\n",
       "      <td>0.586313</td>\n",
       "      <td>0.781561</td>\n",
       "      <td>0.712696</td>\n",
       "      <td>0.763430</td>\n",
       "      <td>0.733120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, Report_Finbert = Finbert.train_predict(X_train_prep, y_train, X_val_prep, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308f9461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     bearish       0.58      0.74      0.65       288\n",
      "     bullish       0.66      0.75      0.70       385\n",
      "     neutral       0.90      0.80      0.85      1236\n",
      "\n",
      "    accuracy                           0.78      1909\n",
      "   macro avg       0.71      0.76      0.73      1909\n",
      "weighted avg       0.80      0.78      0.79      1909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Report_Finbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7634/7634 [00:01<00:00, 5697.25 examples/s]\n",
      "Map: 100%|██████████| 1909/1909 [00:00<00:00, 5539.27 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2390' max='2390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2390/2390 12:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.059872</td>\n",
       "      <td>0.724463</td>\n",
       "      <td>0.437578</td>\n",
       "      <td>0.520217</td>\n",
       "      <td>0.475235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.819300</td>\n",
       "      <td>1.403098</td>\n",
       "      <td>0.179675</td>\n",
       "      <td>0.385113</td>\n",
       "      <td>0.348166</td>\n",
       "      <td>0.118038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.496900</td>\n",
       "      <td>1.054533</td>\n",
       "      <td>0.563122</td>\n",
       "      <td>0.736489</td>\n",
       "      <td>0.506860</td>\n",
       "      <td>0.406404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.359000</td>\n",
       "      <td>0.913722</td>\n",
       "      <td>0.691461</td>\n",
       "      <td>0.608907</td>\n",
       "      <td>0.560390</td>\n",
       "      <td>0.489438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.173600</td>\n",
       "      <td>0.820468</td>\n",
       "      <td>0.735987</td>\n",
       "      <td>0.626729</td>\n",
       "      <td>0.635606</td>\n",
       "      <td>0.630830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, Report_Bertweet = Bertweet.train_predict(X_train_prep, y_train, X_val_prep, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e1a141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     bearish       0.44      0.44      0.44       288\n",
      "     bullish       0.58      0.62      0.60       385\n",
      "     neutral       0.86      0.84      0.85      1236\n",
      "\n",
      "    accuracy                           0.74      1909\n",
      "   macro avg       0.63      0.64      0.63      1909\n",
      "weighted avg       0.74      0.74      0.74      1909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Report_Bertweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf51b1",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models with final parameters \n",
    "Finbert_tuned = TransformerEncoder(num_classes=3, model_name=finbert, base_model=\"BERT\", batch_size=16, learning_rate=3e-5, num_epochs=10)\n",
    "Bertweet_tuned = TransformerEncoder(num_classes=3, model_name=bertweet, base_model=\"ROBERTA\", batch_size=16, learning_rate=3e-5, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c4ddc",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light preprocessing\n",
    "preprocessor = PreprocessingPretrained(translate=True)\n",
    "\n",
    "train_df_prep = preprocessor.preprocess(train_df)\n",
    "\n",
    "X = train_df_prep[\"text\"]\n",
    "y = train_df_prep[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42065e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_transformer(encoder, X, y, model_name, k=5):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    macro_precision = []\n",
    "    macro_recall = []\n",
    "    macro_f1 = []\n",
    "    macro_accuracy = []\n",
    "\n",
    "    weighted_precision = []\n",
    "    weighted_recall = []\n",
    "    weighted_f1 = []\n",
    "\n",
    "    all_class_precisions = []\n",
    "    all_class_recalls = []\n",
    "    all_class_f1s = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "\n",
    "        print(f\"Training fold {fold}/{k}...\") \n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        predictions, report = encoder.train_predict(X_train, y_train, X_val, y_val)\n",
    "\n",
    "        # Macro avg\n",
    "        macro_precision.append(report['macro avg']['precision'])\n",
    "        macro_recall.append(report['macro avg']['recall'])\n",
    "        macro_f1.append(report['macro avg']['f1-score'])\n",
    "        macro_accuracy.append(report['accuracy'])\n",
    "\n",
    "        # Weighted avg\n",
    "        weighted_precision.append(report['weighted avg']['precision'])\n",
    "        weighted_recall.append(report['weighted avg']['recall'])\n",
    "        weighted_f1.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "        # Per-class metrics\n",
    "        for cls, metrics in report.items():\n",
    "            if cls not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                all_class_precisions.append(metrics['precision'])\n",
    "                all_class_recalls.append(metrics['recall'])\n",
    "                all_class_f1s.append(metrics['f1-score'])\n",
    "\n",
    "    \n",
    "    results.append({\n",
    "    'Name': model_name,\n",
    "    'CV_Accuracy': np.mean(macro_accuracy),\n",
    "    'CV_Accuracy_Std': np.std(macro_accuracy),\n",
    "    'CV_Macro_F1': np.mean(macro_f1),\n",
    "    'CV_Macro_F1_Std': np.std(macro_f1),\n",
    "    'CV_Weighted_F1': np.mean(weighted_f1),\n",
    "    'CV_Weighted_F1_Std': np.std(weighted_f1),\n",
    "    'Min_Class_Precision': np.min(all_class_precisions),\n",
    "    'Max_Class_Precision': np.max(all_class_precisions),\n",
    "    'Min_Class_Recall': np.min(all_class_recalls),\n",
    "    'Max_Class_Recall': np.max(all_class_recalls),\n",
    "    'Min_Class_F1': np.min(all_class_f1s),\n",
    "    'Max_Class_F1': np.max(all_class_f1s)\n",
    "    })\n",
    "\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ddef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_transformer(Finbert_tuned, model_name=\"Finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ce502",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_transformer(Bertweet_tuned, model_name=\"Bertweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38120b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "\n",
    "if len(successful_results) > 0:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    x_pos = np.arange(len(successful_results))\n",
    "    ax1.bar(x_pos, successful_results['CV_Accuracy'], \n",
    "            yerr=successful_results['CV_Accuracy_Std'], capsize=5)\n",
    "    ax1.set_title('Cross-Validation Accuracy Comparison')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(successful_results['Name'], rotation=45, ha='right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # F1 Score comparison\n",
    "    ax2.bar(x_pos, successful_results['CV_Macro_F1'], \n",
    "            yerr=successful_results['CV_Macro_F1_Std'], capsize=5, color='orange')\n",
    "    ax2.set_title('Cross-Validation Macro F1 Comparison')\n",
    "    ax2.set_ylabel('Macro F1 Score')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(successful_results['Name'], rotation=45, ha='right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Performance vs Standard Deviation\n",
    "    ax3.scatter(successful_results['CV_Accuracy'], successful_results['CV_Accuracy_Std'])\n",
    "    for i, name in enumerate(successful_results['Name']):\n",
    "        ax3.annotate(name.split(' - ')[0], \n",
    "                    (successful_results['CV_Accuracy'].iloc[i], \n",
    "                     successful_results['CV_Accuracy_Std'].iloc[i]),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    ax3.set_xlabel('CV Accuracy')\n",
    "    ax3.set_ylabel('CV Accuracy Std')\n",
    "    ax3.set_title('Accuracy vs Consistency Trade-off')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ranking by different metrics\n",
    "    metrics = ['CV_Accuracy', 'CV_Macro_F1', 'CV_Weighted_F1']\n",
    "    rankings = {}\n",
    "    for metric in metrics:\n",
    "        rankings[metric] = successful_results.nlargest(3, metric)['Name'].tolist()\n",
    "    \n",
    "    ax4.axis('off')\n",
    "    ranking_text = \"🏆 TOP PERFORMERS:\\n\\n\"\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ranking_text += f\"{metric.replace('CV_', '').replace('_', ' ')}:\\n\"\n",
    "        for j, name in enumerate(rankings[metric]):\n",
    "            ranking_text += f\"  {j+1}. {name.split(' - ')[0]}\\n\"\n",
    "        ranking_text += \"\\n\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, ranking_text, transform=ax4.transAxes, \n",
    "             fontsize=12, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.suptitle('Pipeline Performance Analysis', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d488b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_model = successful_results.loc[successful_results['CV_Weighted_F1'].idxmax()]\n",
    "\n",
    "print(\"\\n🏆 BEST PERFORMING MODEL:\"\n",
    "      f\"\\nName: {winning_model['Name']}\"\n",
    "      f\"\\nCV Accuracy: {winning_model['CV_Accuracy']:.4f} ± {winning_model['CV_Accuracy_Std']:.4f}\"\n",
    "      f\"\\nCV Macro F1: {winning_model['CV_Macro_F1']:.4f} ± {winning_model['CV_Macro_F1_Std']:.4f}\"\n",
    "      f\"\\nCV Weighted F1: {winning_model['CV_Weighted_F1']:.4f} ± {winning_model['CV_Weighted_F1_Std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report of the winning model\n",
    "print(\"\\n📊 Classification Report of Winning Model:\"\n",
    "      \"\\FINBERT\")\n",
    "\n",
    "predictions, Report_Finbert = Finbert.train_predict(X_train_prep, y_train, X_val_prep, y_val)\n",
    "\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".TM_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
