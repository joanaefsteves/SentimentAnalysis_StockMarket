{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abf4e75",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## <center> <b> Stock Sentiment </center>\n",
    "## <center> Predicting market behavior from tweets </center> <br>\n",
    "##  <center> <b> FINAL MODEL </center> <br>\n",
    "## <center> Spring Semester 2024-2025 <center>\n",
    "\n",
    "<center> Group 35: <center>\n",
    "<center>Joana Esteves, 20240746 <br><center>\n",
    "<center>Jos√© Cavaco, 20240513 <br><center>\n",
    "<center> Leonardo Di Caterina 20240485<br><center>\n",
    "<center>Matilde Miguel, 20240549 <br><center>\n",
    "<center>Rita Serra, 20240515 <br><center>\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a8ba0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a7f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanaesteves/Desktop/MDSAA-DS/S2/T4/TM/.TM_Project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b3ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Preprocess\n",
    "from src.preprocessing import PreprocessingPretrained\n",
    "\n",
    "# Model\n",
    "from src.tranformer_encoder import TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ac2050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('../Data/train.csv')\n",
    "test_df = pd.read_csv('../Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de98286",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "            train_df['text'], train_df['label'], \n",
    "            test_size=0.2, stratify=train_df['label'], random_state=seed\n",
    "        )\n",
    "\n",
    "X_test = test_df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ec5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light preprocessing\n",
    "preprocessor = PreprocessingPretrained(translate=True)\n",
    "\n",
    "X_train_prep = preprocessor.preprocess(X_train)\n",
    "X_val_prep = preprocessor.preprocess(X_val)\n",
    "X_test_prep = preprocessor.preprocess(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40b913",
   "metadata": {},
   "source": [
    "# Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494eb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "finbert = \"yiyanghkust/finbert-tone\"\n",
    "Finbert = TransformerEncoder(num_classes=3, model_name=finbert, base_model=\"BERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd263fbc",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6062b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_transformer(encoder, X, y, model_name, k=5):\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    macro_precision = []\n",
    "    macro_recall = []\n",
    "    macro_f1 = []\n",
    "    macro_accuracy = []\n",
    "\n",
    "    weighted_precision = []\n",
    "    weighted_recall = []\n",
    "    weighted_f1 = []\n",
    "\n",
    "    all_class_precisions = []\n",
    "    all_class_recalls = []\n",
    "    all_class_f1s = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "\n",
    "        print(f\"Training fold {fold}/{k}...\") \n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        predictions, report = encoder.train_predict(X_train, y_train, X_val, y_val)\n",
    "\n",
    "        # Macro avg\n",
    "        macro_precision.append(report['macro avg']['precision'])\n",
    "        macro_recall.append(report['macro avg']['recall'])\n",
    "        macro_f1.append(report['macro avg']['f1-score'])\n",
    "        macro_accuracy.append(report['accuracy'])\n",
    "\n",
    "        # Weighted avg\n",
    "        weighted_precision.append(report['weighted avg']['precision'])\n",
    "        weighted_recall.append(report['weighted avg']['recall'])\n",
    "        weighted_f1.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "        # Per-class metrics\n",
    "        for cls, metrics in report.items():\n",
    "            if cls not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                all_class_precisions.append(metrics['precision'])\n",
    "                all_class_recalls.append(metrics['recall'])\n",
    "                all_class_f1s.append(metrics['f1-score'])\n",
    "\n",
    "    \n",
    "    results.append({\n",
    "    'Name': model_name,\n",
    "    'CV_Accuracy': np.mean(macro_accuracy),\n",
    "    'CV_Accuracy_Std': np.std(macro_accuracy),\n",
    "    'CV_Macro_F1': np.mean(macro_f1),\n",
    "    'CV_Macro_F1_Std': np.std(macro_f1),\n",
    "    'CV_Weighted_F1': np.mean(weighted_f1),\n",
    "    'CV_Weighted_F1_Std': np.std(weighted_f1),\n",
    "    'Min_Class_Precision': np.min(all_class_precisions),\n",
    "    'Max_Class_Precision': np.max(all_class_precisions),\n",
    "    'Min_Class_Recall': np.min(all_class_recalls),\n",
    "    'Max_Class_Recall': np.max(all_class_recalls),\n",
    "    'Min_Class_F1': np.min(all_class_f1s),\n",
    "    'Max_Class_F1': np.max(all_class_f1s)\n",
    "    })\n",
    "\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00657e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_model = results.loc[results['CV_Weighted_F1'].idxmax()]\n",
    "\n",
    "print(\"\\nüèÜ BEST PERFORMING MODEL:\"\n",
    "      f\"\\nName: {winning_model['Name']}\"\n",
    "      f\"\\nCV Accuracy: {winning_model['CV_Accuracy']:.4f} ¬± {winning_model['CV_Accuracy_Std']:.4f}\"\n",
    "      f\"\\nCV Macro F1: {winning_model['CV_Macro_F1']:.4f} ¬± {winning_model['CV_Macro_F1_Std']:.4f}\"\n",
    "      f\"\\nCV Weighted F1: {winning_model['CV_Weighted_F1']:.4f} ¬± {winning_model['CV_Weighted_F1_Std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report of the winning model\n",
    "print(\"\\nüìä Classification Report of Winning Model:\"\n",
    "      \"\\FINBERT\")\n",
    "\n",
    "predictions, Report_Finbert = Finbert.train_predict(X_train_prep, y_train, X_val_prep, y_val)\n",
    "\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_val), yticklabels=np.unique(y_val))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6dfee7",
   "metadata": {},
   "source": [
    "# Predict for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69b99c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prep = pd.DataFrame({\n",
    "    'text': X_test_prep,\n",
    "    'id': test_df['id'].values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f6ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8588/8588 [00:00<00:00, 19568.93 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 955/955 [00:00<00:00, 25650.03 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2388/2388 [00:00<00:00, 25795.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2685' max='2685' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2685/2685 18:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.128400</td>\n",
       "      <td>0.763706</td>\n",
       "      <td>0.784293</td>\n",
       "      <td>0.718657</td>\n",
       "      <td>0.748945</td>\n",
       "      <td>0.729604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.779668</td>\n",
       "      <td>0.717277</td>\n",
       "      <td>0.702060</td>\n",
       "      <td>0.756658</td>\n",
       "      <td>0.697831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.801400</td>\n",
       "      <td>0.699396</td>\n",
       "      <td>0.736126</td>\n",
       "      <td>0.694975</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>0.697957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.572064</td>\n",
       "      <td>0.767539</td>\n",
       "      <td>0.706760</td>\n",
       "      <td>0.788413</td>\n",
       "      <td>0.731538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.787435</td>\n",
       "      <td>0.720679</td>\n",
       "      <td>0.788546</td>\n",
       "      <td>0.745981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, _ = Finbert.train_predict(X_train_prep, y_train, X_val_prep, y_val, X_test_prep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM_Project",
   "language": "python",
   "name": "tm_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
