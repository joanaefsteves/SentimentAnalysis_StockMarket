{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Testing and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9543, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "99066312-e5af-4043-a43c-7f86a46c0849",
       "rows": [
        [
         "0",
         "$BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT",
         "0"
        ],
        [
         "1",
         "$CCL $RCL - Nomura points to bookings weakness at Carnival and Royal Caribbean https://t.co/yGjpT2ReD3",
         "0"
        ],
        [
         "2",
         "$CX - Cemex cut at Credit Suisse, J.P. Morgan on weak building outlook https://t.co/KN1g4AWFIb",
         "0"
        ],
        [
         "3",
         "$ESS: BTIG Research cuts to Neutral https://t.co/MCyfTsXc2N",
         "0"
        ],
        [
         "4",
         "$FNKO - Funko slides after Piper Jaffray PT cut https://t.co/z37IJmCQzB",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$BYND - JPMorgan reels in expectations on Beyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$CCL $RCL - Nomura points to bookings weakness...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$CX - Cemex cut at Credit Suisse, J.P. Morgan ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$ESS: BTIG Research cuts to Neutral https://t....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$FNKO - Funko slides after Piper Jaffray PT cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  $BYND - JPMorgan reels in expectations on Beyo...      0\n",
       "1  $CCL $RCL - Nomura points to bookings weakness...      0\n",
       "2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0\n",
       "3  $ESS: BTIG Research cuts to Neutral https://t....      0\n",
       "4  $FNKO - Funko slides after Piper Jaffray PT cu...      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "from wordcloud import WordCloud # type: ignore\n",
    "from collections import Counter # type: ignore\n",
    "\n",
    "# Load data\n",
    "data_folder = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "data_train = pd.read_csv(os.path.join(data_folder, 'train.csv'))\n",
    "print(f\"Dataset shape: {data_train.shape}\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/leonardodicaterina/Desktop/NovaIMS/TextMining/TM_Project/Notebooks\n",
      "Changed working directory to: /Users/leonardodicaterina/Desktop/NovaIMS/TextMining/TM_Project\n"
     ]
    }
   ],
   "source": [
    "# Change to parent directory to import preprocessing\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(\"Changed working directory to:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Preprocessing modules initialized\n"
     ]
    }
   ],
   "source": [
    "from src.preprocessing import Preprocessing\n",
    "\n",
    "Preprocessing_instance = Preprocessing(lemmatize=True, stem=False)\n",
    "\n",
    "# Initialize preprocessing with different configurations\n",
    "preprocessor_lemma = Preprocessing(lemmatize=True, stem=False, emoji_support_level=1)\n",
    "preprocessor_stem = Preprocessing(lemmatize=False, stem=True, emoji_support_level=1)\n",
    "preprocessor_both = Preprocessing(lemmatize=True, stem=True, emoji_support_level=1)\n",
    "\n",
    "print(\"Preprocessing modules initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample raw texts:\n",
      "\n",
      "1. $BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT...\n",
      "\n",
      "2. $CCL $RCL - Nomura points to bookings weakness at Carnival and Royal Caribbean https://t.co/yGjpT2ReD3...\n",
      "\n",
      "3. $CX - Cemex cut at Credit Suisse, J.P. Morgan on weak building outlook https://t.co/KN1g4AWFIb...\n"
     ]
    }
   ],
   "source": [
    "# Sample some texts for detailed analysis\n",
    "sample_texts = data_train['text'].head(10).tolist()\n",
    "\n",
    "print(\"Sample raw texts:\")\n",
    "for i, text in enumerate(sample_texts[:3], 1):\n",
    "    print(f\"\\n{i}. {text[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text word count statistics:\n",
      "count    9543.000000\n",
      "mean       12.168081\n",
      "std         4.651245\n",
      "min         1.000000\n",
      "25%         9.000000\n",
      "50%        11.000000\n",
      "75%        15.000000\n",
      "max        31.000000\n",
      "Name: word_count_raw, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Word count analysis before preprocessing\n",
    "data_train['word_count_raw'] = data_train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data_train['word_count_raw'], bins=50, alpha=0.7, color='skyblue')\n",
    "plt.title('Raw Text Word Count Distribution')\n",
    "plt.xlabel('Word Count')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=data_train['word_count_raw'])\n",
    "plt.title('Raw Text Word Count Box Plot')\n",
    "plt.xlabel('Word Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Raw text word count statistics:\")\n",
    "print(data_train['word_count_raw'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing emojis with support level 1\n",
      "Initial texts: $bynd - jpmorgan reels in expectations on beyond meat URL\n",
      "Processing text: $\n",
      "ord values: [36]\n",
      "Processing text: b\n",
      "ord values: [98]\n",
      "Processing text: y\n",
      "ord values: [121]\n",
      "Processing text: n\n",
      "ord values: [110]\n",
      "Processing text: d\n",
      "ord values: [100]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: -\n",
      "ord values: [45]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: j\n",
      "ord values: [106]\n",
      "Processing text: p\n",
      "ord values: [112]\n",
      "Processing text: m\n",
      "ord values: [109]\n",
      "Processing text: o\n",
      "ord values: [111]\n",
      "Processing text: r\n",
      "ord values: [114]\n",
      "Processing text: g\n",
      "ord values: [103]\n",
      "Processing text: a\n",
      "ord values: [97]\n",
      "Processing text: n\n",
      "ord values: [110]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: r\n",
      "ord values: [114]\n",
      "Processing text: e\n",
      "ord values: [101]\n",
      "Processing text: e\n",
      "ord values: [101]\n",
      "Processing text: l\n",
      "ord values: [108]\n",
      "Processing text: s\n",
      "ord values: [115]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: i\n",
      "ord values: [105]\n",
      "Processing text: n\n",
      "ord values: [110]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: e\n",
      "ord values: [101]\n",
      "Processing text: x\n",
      "ord values: [120]\n",
      "Processing text: p\n",
      "ord values: [112]\n",
      "Processing text: e\n",
      "ord values: [101]\n",
      "Processing text: c\n",
      "ord values: [99]\n",
      "Processing text: t\n",
      "ord values: [116]\n",
      "Processing text: a\n",
      "ord values: [97]\n",
      "Processing text: t\n",
      "ord values: [116]\n",
      "Processing text: i\n",
      "ord values: [105]\n",
      "Processing text: o\n",
      "ord values: [111]\n",
      "Processing text: n\n",
      "ord values: [110]\n",
      "Processing text: s\n",
      "ord values: [115]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: o\n",
      "ord values: [111]\n",
      "Processing text: n\n",
      "ord values: [110]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: b\n",
      "ord values: [98]\n",
      "Processing text: e\n",
      "ord values: [101]\n",
      "Processing text: y\n",
      "ord values: [121]\n",
      "Processing text: o\n",
      "ord values: [111]\n",
      "Processing text: n\n",
      "ord values: [110]\n",
      "Processing text: d\n",
      "ord values: [100]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: m\n",
      "ord values: [109]\n",
      "Processing text: e\n",
      "ord values: [101]\n",
      "Processing text: a\n",
      "ord values: [97]\n",
      "Processing text: t\n",
      "ord values: [116]\n",
      "Processing text:  \n",
      "ord values: [32]\n",
      "Processing text: U\n",
      "ord values: [85]\n",
      "Processing text: R\n",
      "ord values: [82]\n",
      "Processing text: L\n",
      "ord values: [76]\n",
      "ASCII cleaned text: ['', 'b', 'y', 'n', 'd', '', '', '', 'j', 'p', 'm', 'o', 'r', 'g', 'a', 'n', '', 'r', 'e', 'e', 'l', 's', '', 'i', 'n', '', 'e', 'x', 'p', 'e', 'c', 't', 'a', 't', 'i', 'o', 'n', 's', '', 'o', 'n', '', 'b', 'e', 'y', 'o', 'n', 'd', '', 'm', 'e', 'a', 't', '', 'U', 'R', 'L']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m test_texts = sample_texts[:\u001b[32m5\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Apply different preprocessing approaches\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m processed_lemma = \u001b[43mpreprocessor_lemma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m processed_stem = preprocessor_stem.preprocess(test_texts)\n\u001b[32m      7\u001b[39m processed_both = preprocessor_both.preprocess(test_texts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NovaIMS/TextMining/TM_Project/src/preprocessing.py:62\u001b[39m, in \u001b[36mPreprocessing.preprocess\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NovaIMS/TextMining/TM_Project/src/preprocessing.py:95\u001b[39m, in \u001b[36mPreprocessing._clean_text\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     93\u001b[39m ascii_text  = \u001b[38;5;28mself\u001b[39m.final_ascii_clean(text)\n\u001b[32m     94\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mASCII cleaned text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mascii_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging line to print ASCII cleaned text\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m tokens = \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascii_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Remove punctuation and stopwords\u001b[39;00m\n\u001b[32m     98\u001b[39m tokens = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m (t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.punctuation \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stopwords)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/__init__.py:120\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    119\u001b[39m tokenizer = _get_punkt_tokenizer(language)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1280\u001b[39m, in \u001b[36mPunktSentenceTokenizer.tokenize\u001b[39m\u001b[34m(self, text, realign_boundaries)\u001b[39m\n\u001b[32m   1276\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m   1277\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1278\u001b[39m \u001b[33;03m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msentences_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1340\u001b[39m, in \u001b[36mPunktSentenceTokenizer.sentences_from_text\u001b[39m\u001b[34m(self, text, realign_boundaries)\u001b[39m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msentences_from_text\u001b[39m(\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, realign_boundaries: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1333\u001b[39m ) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m   1334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1335\u001b[39m \u001b[33;03m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[32m   1336\u001b[39m \u001b[33;03m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[32m   1337\u001b[39m \u001b[33;03m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[32m   1338\u001b[39m \u001b[33;03m    follows the period.\u001b[39;00m\n\u001b[32m   1339\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1340\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mspan_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign_boundaries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1328\u001b[39m, in \u001b[36mPunktSentenceTokenizer.span_tokenize\u001b[39m\u001b[34m(self, text, realign_boundaries)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m realign_boundaries:\n\u001b[32m   1327\u001b[39m     slices = \u001b[38;5;28mself\u001b[39m._realign_boundaries(text, slices)\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mslices\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1457\u001b[39m, in \u001b[36mPunktSentenceTokenizer._realign_boundaries\u001b[39m\u001b[34m(self, text, slices)\u001b[39m\n\u001b[32m   1444\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1445\u001b[39m \u001b[33;03mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[32m   1446\u001b[39m \u001b[33;03mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1454\u001b[39m \u001b[33;03m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[32m   1455\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1456\u001b[39m realign = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1457\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_pair_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1458\u001b[39m \u001b[43m    \u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence2\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/punkt.py:321\u001b[39m, in \u001b[36m_pair_iter\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    319\u001b[39m iterator = \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     prev = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1429\u001b[39m, in \u001b[36mPunktSentenceTokenizer._slices_from_text\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m   1427\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_slices_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> Iterator[\u001b[38;5;28mslice\u001b[39m]:\n\u001b[32m   1428\u001b[39m     last_break = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1429\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_match_potential_end_contexts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1430\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext_contains_sentbreak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_break\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/Text_env/lib/python3.12/site-packages/nltk/tokenize/punkt.py:1394\u001b[39m, in \u001b[36mPunktSentenceTokenizer._match_potential_end_contexts\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m   1392\u001b[39m previous_slice = \u001b[38;5;28mslice\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m   1393\u001b[39m previous_match = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lang_vars\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperiod_context_re\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinditer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;66;03m# Get the slice of the previous word\u001b[39;00m\n\u001b[32m   1396\u001b[39m     before_text = text[previous_slice.stop : match.start()]\n\u001b[32m   1397\u001b[39m     index_after_last_space = \u001b[38;5;28mself\u001b[39m._get_last_whitespace_index(before_text)\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'list'"
     ]
    }
   ],
   "source": [
    "# Test preprocessing on sample texts\n",
    "test_texts = sample_texts[:5]\n",
    "\n",
    "# Apply different preprocessing approaches\n",
    "processed_lemma = preprocessor_lemma.preprocess(test_texts)\n",
    "processed_stem = preprocessor_stem.preprocess(test_texts)\n",
    "processed_both = preprocessor_both.preprocess(test_texts)\n",
    "\n",
    "# Compare results\n",
    "for i, (raw, lemma, stem, both) in enumerate(zip(test_texts, processed_lemma, processed_stem, processed_both), 1):\n",
    "    print(f\"\\n=== Text {i} ===\")\n",
    "    print(f\"Raw ({len(raw.split())} words): {raw[:100]}...\")\n",
    "    print(f\"Lemmatized ({len(lemma)} tokens): {' '.join(lemma[:15])}...\")\n",
    "    print(f\"Stemmed ({len(stem)} tokens): {' '.join(stem[:15])}...\")\n",
    "    print(f\"Both ({len(both)} tokens): {' '.join(both[:15])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset Preprocessing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a subset for analysis (first 1000 samples to avoid memory issues)\n",
    "subset_size = 1000\n",
    "subset_texts = data_train['text'].head(subset_size).tolist()\n",
    "\n",
    "processed_subset = preprocessor_lemma.preprocess(subset_texts)\n",
    "\n",
    "# Calculate token counts after preprocessing\n",
    "token_counts = [len(tokens) for tokens in processed_subset]\n",
    "\n",
    "print(f\"\\nToken count statistics after preprocessing:\")\n",
    "print(f\"Mean: {np.mean(token_counts):.2f}\")\n",
    "print(f\"Median: {np.median(token_counts):.2f}\")\n",
    "print(f\"Min: {np.min(token_counts)}\")\n",
    "print(f\"Max: {np.max(token_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare word counts before and after preprocessing\n",
    "raw_word_counts = [len(text.split()) for text in subset_texts]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(raw_word_counts, bins=30, alpha=0.7, label='Raw', color='lightcoral')\n",
    "plt.hist(token_counts, bins=30, alpha=0.7, label='Processed', color='lightblue')\n",
    "plt.title('Word/Token Count Comparison')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "reduction_ratio = [(raw - proc) / raw * 100 for raw, proc in zip(raw_word_counts, token_counts) if raw > 0]\n",
    "plt.hist(reduction_ratio, bins=30, alpha=0.7, color='lightgreen')\n",
    "plt.title('Token Reduction Percentage')\n",
    "plt.xlabel('Reduction %')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average token reduction: {np.mean(reduction_ratio):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all tokens and analyze vocabulary\n",
    "all_tokens = [token for tokens in processed_subset for token in tokens]\n",
    "tokens_to_remove = preprocessor_stem.get_normalized_patterns()\n",
    "# Remove specified tokens\n",
    "all_tokens = [token for token in all_tokens if token not in tokens_to_remove]\n",
    "\n",
    "\n",
    "vocab_counter = Counter(all_tokens)\n",
    "\n",
    "print(f\"Total tokens: {len(all_tokens):,}\")\n",
    "print(f\"Unique tokens (vocabulary size): {len(vocab_counter):,}\")\n",
    "print(f\"Vocabulary richness: {len(vocab_counter)/len(all_tokens):.4f}\")\n",
    "\n",
    "# Most common tokens\n",
    "print(f\"\\nTop 20 most common tokens:\")\n",
    "for token, count in vocab_counter.most_common(20):\n",
    "    print(f\"{token}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token frequency distribution\n",
    "token_frequencies = list(vocab_counter.values())\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(token_frequencies, bins=50, alpha=0.7, color='gold')\n",
    "plt.title('Token Frequency Distribution')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Number of Tokens')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "# Rank-frequency plot (Zipf's law)\n",
    "ranks = range(1, len(token_frequencies) + 1)\n",
    "sorted_frequencies = sorted(token_frequencies, reverse=True)\n",
    "plt.loglog(ranks, sorted_frequencies, alpha=0.7, color='purple')\n",
    "plt.title('Rank-Frequency Plot')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Top 30 tokens bar plot\n",
    "top_tokens = vocab_counter.most_common(30)\n",
    "tokens, counts = zip(*top_tokens)\n",
    "plt.barh(range(len(tokens)), counts, color='lightsteelblue')\n",
    "plt.yticks(range(len(tokens)), tokens)\n",
    "plt.title('Top 30 Tokens')\n",
    "plt.xlabel('Frequency')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot tests Zipf's Law, which states that in natural language:\n",
    "\n",
    "The most frequent word appears about twice as often as the 2nd most frequent\n",
    "Three times as often as the 3rd most frequent\n",
    "And so on...\n",
    "In a log-log plot, Zipf's Law appears as a straight line with negative slope (approximately -1).\n",
    "\n",
    "Interpretation:\n",
    "Straight diagonal line: Your text follows Zipf's Law (typical for natural language)\n",
    "Curved or irregular line: Deviation from expected language patterns\n",
    "Steep slope: High concentration of frequent words\n",
    "Gentle slope: More even distribution of word frequencies\n",
    "This analysis helps you understand the vocabulary distribution in your preprocessed text data and validate that your preprocessing maintains natural language characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Clouds Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for raw vs processed text\n",
    "raw_text = ' '.join(subset_texts).lower()\n",
    "processed_text = ' '.join(all_tokens)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Raw text word cloud\n",
    "plt.subplot(1, 2, 1)\n",
    "raw_wc = WordCloud(width=600, height=400, background_color='white', max_words=100).generate(raw_text)\n",
    "plt.imshow(raw_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - Raw Text', fontsize=14)\n",
    "\n",
    "# Processed text word cloud\n",
    "plt.subplot(1, 2, 2)\n",
    "processed_wc = WordCloud(width=600, height=400, background_color='white', max_words=100).generate(processed_text)\n",
    "plt.imshow(processed_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - Processed Text', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pattern Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test specific preprocessing patterns\n",
    "test_patterns = [\n",
    "    \"Check out this amazing deal at $50.99! Visit https://example.com for more info #sale @company\",\n",
    "    \"The stock $AAPL is trading at 150.00. What a wonderful day!!!\",\n",
    "    \"Follow @username for updates. #investing #stocks www.example.com\",\n",
    "    \"This costs $25,000 approximately. Really expensive!!!\"\n",
    "]\n",
    "\n",
    "print(\"Pattern replacement testing:\")\n",
    "for i, text in enumerate(test_patterns, 1):\n",
    "    processed = preprocessor_lemma.preprocess([text])[0]\n",
    "    print(f\"\\n{i}. Original: {text}\")\n",
    "    print(f\"   Processed: {' '.join(processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Performance comparison between different preprocessing approaches\n",
    "test_batch = data_train['text'].head(100).tolist()\n",
    "\n",
    "# Test different configurations\n",
    "configs = [\n",
    "    ('Lemmatization only', Preprocessing(lemmatize=True, stem=False)),\n",
    "    ('Stemming only', Preprocessing(lemmatize=False, stem=True)),\n",
    "    ('Both', Preprocessing(lemmatize=True, stem=True)),\n",
    "    ('Neither', Preprocessing(lemmatize=False, stem=False))\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, preprocessor in configs:\n",
    "    start_time = time.time()\n",
    "    processed = preprocessor.preprocess(test_batch)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    avg_tokens = np.mean([len(tokens) for tokens in processed])\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    results.append({\n",
    "        'Configuration': name,\n",
    "        'Processing Time (s)': processing_time,\n",
    "        'Avg Tokens per Text': avg_tokens,\n",
    "        'Texts per Second': len(test_batch) / processing_time\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Performance Comparison:\")\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Processing time\n",
    "ax1.bar(results_df['Configuration'], results_df['Processing Time (s)'], color='lightcoral')\n",
    "ax1.set_title('Processing Time by Configuration')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Average tokens\n",
    "ax2.bar(results_df['Configuration'], results_df['Avg Tokens per Text'], color='lightblue')\n",
    "ax2.set_title('Average Tokens per Text')\n",
    "ax2.set_ylabel('Token Count')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Throughput\n",
    "ax3.bar(results_df['Configuration'], results_df['Texts per Second'], color='lightgreen')\n",
    "ax3.set_title('Processing Throughput')\n",
    "ax3.set_ylabel('Texts per Second')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Summary table\n",
    "ax4.axis('tight')\n",
    "ax4.axis('off')\n",
    "table = ax4.table(cellText=results_df.round(3).values, \n",
    "                  colLabels=results_df.columns,\n",
    "                  cellLoc='center',\n",
    "                  loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(8)\n",
    "ax4.set_title('Performance Summary')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PREPROCESSING ANALYSIS SUMMARY ===\")\n",
    "print(f\"\\n Dataset Overview:\")\n",
    "print(f\"    Total samples analyzed: {subset_size}\")\n",
    "print(f\"    Average raw word count: {np.mean(raw_word_counts):.1f}\")\n",
    "print(f\"    Average processed token count: {np.mean(token_counts):.1f}\")\n",
    "\n",
    "print(f\"\\n Vocabulary Analysis:\")\n",
    "print(f\"    Total tokens: {len(all_tokens):,}\")\n",
    "print(f\"    Unique vocabulary: {len(vocab_counter):,}\")\n",
    "print(f\"    Vocabulary richness: {len(vocab_counter)/len(all_tokens):.4f}\")\n",
    "\n",
    "print(f\"\\n Performance Insights:\")\n",
    "best_throughput = results_df.loc[results_df['Texts per Second'].idxmax()]\n",
    "print(f\"    Fastest configuration: {best_throughput['Configuration']}\")\n",
    "print(f\"    Best throughput: {best_throughput['Texts per Second']:.1f} texts/second\")\n",
    "\n",
    "print(f\"\\n Recommendations:\")\n",
    "print(f\"    Average token reduction: {np.mean(reduction_ratio):.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
